[{"authors":null,"categories":null,"content":"It\u0026rsquo;s has been a long time since I last posted an article not related to a coursework at UIC. But, I would like to change this trend and would try to post about my learnings and experiences more often from now on.\nThere are few moments in life where a person discovers something and things start making some sort of sense after that.It is has been two years since I joined graduate school at University of Illinois at Chicago to pursue my Masters. People always talk about the specialization they want to do in the masters(If you are computer science student like me, you might have heard about terms like software engineering, security , network , AI, ML , data science, etc.), but for me it was a still a exploratory phase in terms of what I wanted to do in terms of specialization in my field when I came to UIC. I had a inclination towards Artificial Intelligence because of the fascination the field bring alongs with it and mainly because the possibilities it has opened up for the people all around the world in terms of creating several opportunities to solve various real-world problems. I think I liked the uncertainty in my specialization at the beginning because it allowed me to explore and learn more about the various opportunities that I had before narrowing down my options and focusing on a single domain.\nI will now talk about how everything started to make sense over a period of time. I have learnt through my experience that things do not make sense at the beginning but once you spent some time and thought over them, the puzzle starts to makes sense eventually. During my first semester at UIC, I wanted to take courses in Artificial Intelligence and Machine Learning. I also had an interest in Distributed Systems because of the type of work I used to do in my previous job before coming to UIC. But, there was one problem which made it difficult for me to take the courses I wanted to take. It was the high demand of courses like AI, ML and Cloud Computing and the shortage of seats to accomodate all the students. I still remember the day that I had to take a demanding test in order to enroll in the Introduction to Machine Learning (IML) course in the first semester. I luckily passed the test and was able to take that course (I don\u0026rsquo;t know whether I was lucky, because the course was hard and was fun at the same time. But, I have seen overtime that good things are never easy!!). I was not able to register for any of the AI courses because of their popular demand. I did manage to take the cloud computing course and it was one of the most challenging and interesting course I had taken during my time at UIC. Along with all this, I unexpectedly got a teaching assistantship during my first semester where I had the opportunity to teach the undergraduates one of their course. I have always loved talking to people , sharing knowledge and exchanging ideas with them. This opportunity was something I was looking forward to with great enthusiasm. But, academics along with work sometimes could be a bit too much to handle(more on this sometime later). I also took the Algorithms course because everyone should know how to create efficient algorithms :)\nSo, there I was at my first semester of my Masters program, trying to grapple with the mysterious mathematics and statistics of machine learning, trying to decipher the world of mappers and reducers in the cloud and trying to better the Big O\u0026rsquo;s for my algorithms. It was interesting, challenging and fun at the same time and I was you could say in a \u0026ldquo;zone\u0026rdquo; where I never felt the workload because I was enjoying every bit of the things I was doing on the daily basis(I realised why people say do what you love and you will never work a day in your life!!)\nI finished my fall semester with good grades in all my courses but still with a question mark over what to focus on during the rest of the masters coursework. The only solution was to take more courses in order to learn more about my interests in any particular field and see where it went from there on. I decided to take the next level of courses in Machine Learning (the advance level course) and in software engineering (the advance level course). When I think now, the advance machine learning course was and is still one of the hardest course I had taken during my stay at UIC and it was an amazing course. I think the course made me more aware of my interests in the field of machine learning and how serious I was to do something in that field. The advance software engineering was also a interesting course but my interest in that tapered off a bit in that semester.\nMy first year was an exploratory phase and I think it made me more aware of my interests and strengths at the same time. It was not until the third semester, that I had some clarity over what to focus on during my masters.I decided to do a research project in applied machine learning under the guidance of a very good professor at UIC and at the same time I took the Statistical Natural Language Processing course to learn more about the use of statistics in languages processing. It was during this semester that \u0026ldquo;aha moment\u0026rdquo; came for me and things started making more sense and I was more aware of what I wanted to do in the future. I think I never looked back from there and had a clear idea with what I wanted to do from there on. I was happy with how the various things were shaping up and was really looking forward to learn more about machine learning and potential it has to shape the future. It was during this semester I started this blog and wanted to share about my journey and experiences with the rest of the world.\nI finished my last semester last week by taking two more courses including Language and Vision , Visualization and Visual Analytics. Both of them were interesting and challenging but taught me so many new things about the research going on in the field of computer vision and natural language and visualization tools available for us to develop real world applications(If you want to learn more about them, look them up in the projects section of this blog). The journey was full of ups and downs(I am not sure which of them were more!!) but it was something which I could have never planned and thought of at the beginning of my program at UIC. I took up things by interests , made choices as new things came along, persisted with things which I enjoyed and things fell into place eventually. I still have a lot to learn in the field as I think I have just started to find my feet a bit now. I am hoping to expand my knowledge more and apply the same as I enter the next phase of my life after my masters. I am hoping the next phase would be as eventful as the last two years!!\nI hope your enjoyed reading about my experience. I will be back with something more soon. Stay tuned !!!\n","date":1557288000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525753380,"objectID":"66ee2d31e524426ed0da3948e28ccf67","permalink":"https://bhavesh00.github.io/post/aha_moment/","publishdate":"2019-05-07T23:00:00-05:00","relpermalink":"/post/aha_moment/","section":"post","summary":"My journey into field of machine learning and how it all started !!!","tags":["others"],"title":"That aha moment!!","type":"post"},{"authors":null,"categories":null,"content":"This is the third project for the CS 424 Visualization and Visual Analytics class at UIC. It consists in Chicago real-time air quality and weather data visualizations in an interactive web application created using the R Shiny library.\nYou can access the application from here .\nYou can learn more about the application here.\nThe code for the application is available on github .\nAn short video demonstration of the application is available on youtube .\n","date":1557018000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557019380,"objectID":"89f4d3a9e8106a9bd3032cc3e42303a2","permalink":"https://bhavesh00.github.io/project/evlproject3/","publishdate":"2019-05-04T20:00:00-05:00","relpermalink":"/project/evlproject3/","section":"project","summary":"Visualization and Visual Analytics - Project 3!!","tags":["Visualization"],"title":"Chicago Real-Time AQ !!","type":"project"},{"authors":null,"categories":null,"content":"Link to the visualization : Good Governments Help People Succeed\n \u0026ldquo;The care of human life and happiness, and not their destruction, is the first and only object of good government.\u0026rdquo; - Thomas Jefferson\n Purpose of Visualization\nHow can we measure the success of a government and what criteria should be used to label a government as \u0026ldquo;good government\u0026rdquo; ?\nGross Domestic Product (GDP) is commonly used as a metric to compare two countries and their government. Gross Domestic Product is the total value of goods and services provided by a country during one year. The more the output and GDP of a country, it is implied that better is their government and that country is ranked higher in the government ranking.\nBut, metrics like GDP which rely on economic progress of a country do not explain how is the government good or bad for the people living under the rule of that government. We can not conclude that people of a country with a high GDP are living a high quality of life.\nTo learn more about the quality of government there is need to look at other factors like social well being and the impact of government on individual development.\nThis visualization helps in learning about the various measures which make a good government.\nGeneral Dataset Information and Collection\nThe dataset was provided as part of the dataviz challenge organized in partnership with the World Government Summit.\nThe data set can be accessed from this location What Makes A “Good” Government?\nThe data was collected and aggregated from various organizations: Food and Agriculture Organization of United Nations(FAO), World Bank, CIA World Factbook, Happy Planet Index, United Nations Development Programme, World Happiness Report, Boston Consulting Group (BCG) , Heritage Foundation , Freedom House.\nSome features of the dataset:\n The dataset has various measures to access the quality of governments all around the world.\n The dataset contains information for 200 countries for the various measures.\n Some of the attributes present in the dataset are country name, population, GDP, GINI index, HDI, health and education expenditure, economic freedom, etc.\n  Target audience and users for the visualization\n The dataset can be used by any person around the world to learn more about the performance of their government.\n The data would be helpful for the leaders and people in power to get feedback about their performance and know the areas of improvement.\n It can be used by the various country leaders in the world to make decisions and policies for the development of their country and future of their people.\n  Questions people are interested in !!\nThe original goal of measuring the success of a government would require answers to questions listed below. Based on the various measures provided in the dataset, the following questions would be helpful in learning more about the government of a country.\n What measures other than GDP can be used to measure a government\u0026rsquo;s performance?\n How can we learn about what impact the government is having on the people\u0026rsquo;s lives of that country?\n How do governments compare in any particular region of the world (Africa,Americas,Asia,Europe and Oceania)?\n Which countries are ranked higher based on the individual measures like GDP,HDI,Economic Freedom, Gini index?\n Is there any correlation between various metrics like HDI,Economic Freedom score,GINI index and GDP?\n How do measures like HDI, GINI, Economic Freedom score change relative to GDP over a period of time for the various countries?\n How the different countries differ on change of HDI, GINI index and Economic Freedom score with respect to GDP and each other of them?\n  Using the visualization tool to answer the user questions !!\nThe visualization makes use of three more metrics other than GDP to learn more about impact of government on individuals.\nHuman development index(HDI)\nIt is a statistic composite index of life expectancy, education, and per capita income indicators. These indicators are used to rank countries into four tiers of human development. Countries with high lifespan, education level and GNI (PPP) per capita are ranked higher as per the index.\nEconomic Freedom Score\nIt is used to measure the degree of economic freedom in a country on a scale from 0 to 100. Economic Freedom Score is based on four complex sets of indicators: Rule of Law, Limited Government, Regulatory Efficiency and Open Markets. It tells about how any government promotes the freedom to work, produce, consume, and invest in any way for any individual in that country.\nGini Index\nThis metric is used to learn about the status of economic inequality, measure income distribution or wealth distribution amongst a population. Whether the distribution of individual or family income is equal or not can be derived using this measure. Lower value of GINI index means distribution of wealth is more equal in that country as compared to countries having a high GINI index.\nThe visualization tool helps in answering the above questions through it various features. The main features of the tool and corresponding visualizations for them gathered with the help of the tool are described below.\nThere are three main types of visualizations present in the tool.\n1) Scatterplots : These can be used to learn about correlation between various measures.\nThe visualization below shows how Human Development Index and Economic Freedom Score change with respect to GDP per capita for a country.\n2) Collection of line charts : These can be used to see the progress over time for various measures.\nThe visualization below shows how Human Development Index changes with respect to GDP per capita for different countries over the years.\nThe visualization below shows how GINI Index changes with respect to GDP per capita for different countries over the years.\n3) Linecharts for comparsion : These can be used to compare various countries over different measures. This can be done at country level or global level to scale the measures accordingly. The results can also be sorted on various measures to get more insights.\nThe visualization below shows how Economic Freedom Score changes with respect to GDP per capita for top performing countries based on GDP.\nThe visualization below shows how the countries in various regions perform based on change of HDI with respect of GDP per capita. One country from each region was selected for this visualization. The scale used here for comparison is global scale for measures.\nThe visualization below shows how Human Development Index changes with respect to GDP per capita for top performing countries based on GDP.\nThe visualization below shows how Economic Freedom Score changes with respect to GINI index for top performing countries based on Economic Freedom.The scale used here for comparison is country-level scale.\nThe visualization below shows how GINI index changes with respect to GDP per capita for top performing countries based on GDP.\nGood aspects of the visualization\n All the plots in the visualization are well labeled. Both the axis in the plots have descriptive names. It is easy to understand what measures are being visualized through the plot.\n The points on the plots either have labels or have tool-tips for more information.\n The comparison plots have appropriate title at the top for the country names along with the labels for various measures.\n The comparison plots for the various countries allows use to select any metric and sort the results using any other metric. This is very useful to learn more about the various countries and rank them based on various measures.\n The comparison plots provide two options for scaling : country-level and global level. As the values of measures vary for different countries,this feature helps in analyzing the data with respect to global level and country level as required by the user. This handles the range of values for different measures appropriately.\n While performing comparison, the number of countries for which data is available is mentioned at the top for the user. So, the user has an idea of what is the size of the group used for comparison. This figure changes on various measures based on availability of data.\n The scale for both the axis is chosen appropriately based on the type of measure being plotted. This adjusts the plot appearance according to the range of values.\n There is a tool-tip for additional information about the points on the scatterplot and line charts. For scatterplot, the tool-tip shows the value being referred to at the instance. For yearly charts, it has the year information to tell the year also for that point. This helps the user to learn more about a particular country in the visualization.\n The over the years line charts provide the feature to highlight any country from the set of all countries. This allows user to focus on a particular country at a time.\n  Thing which need improvement\n While the line charts over the years help us in learning the progress of a country, having all of them in a single chart can be confusing for the user to interpret the data. The plot could have had the option to remove all other countries rather than just highlighting one of them.\n The highlighting of a particular country in the line chart shows information about that country. But, it is difficult to navigate over different years for that country while highlighting the same country. This could have been avoided by allowing user to select the line for the country and keeping it constant until the next country selection.\n The color palette used in the legend for the years sometimes makes it difficult to differentiate between two consecutive years. This makes it very difficult to compare two consecutive years performance for a particular country. It could be improved to support more years and add clarity in the different years.\n The comparison line charts connect the various points of different measure over the years. As, the line progresses over time, it makes use of the time measure(legend) along with the x and y measures, it is sometimes difficult for user to understand the flow of the charts using them as values are changed over time.\n For few measures in the comparison plot, data for some countries is not available, currently the country is not found in the list of selection, but the same could be communicated to user by a user friendly message.\n  All images used in this post were created using the following visualization tool.\n","date":1555192800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1523661780,"objectID":"ba5263519c945705a813ed2530f68ca6","permalink":"https://bhavesh00.github.io/post/good_gov/","publishdate":"2019-04-13T17:00:00-05:00","relpermalink":"/post/good_gov/","section":"post","summary":"EVL Viewer's Choice Presentation !!","tags":["Visualization"],"title":"Good Governments Help People Succeed!!","type":"post"},{"authors":null,"categories":null,"content":"This is the second project for the CS 424 Visualization and Visual Analytics class at UIC. It consists in various visualizations and interactive plots in a web application created using the Shiny library for R. The visualizations are about the Air Quality dataset by County in the United States and Italy, concentrating on the yearly, daily and hourly data.\nYou can access the application from here .\nYou can learn more about the application here.\nThe code for the application is available on github .\nAn short video demonstration of the application is available on youtube .\n","date":1553104800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550690580,"objectID":"5cc7f003870e06ca5494fe7a1e0fb144","permalink":"https://bhavesh00.github.io/post/evlproject2/","publishdate":"2019-03-20T13:00:00-05:00","relpermalink":"/post/evlproject2/","section":"post","summary":"Visualization and Visual Analytics - Project 2!!","tags":["Visualization"],"title":"Every Breath You Take !!","type":"post"},{"authors":null,"categories":null,"content":"This is the second project for the CS 424 Visualization and Visual Analytics class at UIC. It consists in various visualizations and interactive plots in a web application created using the Shiny library for R. The visualizations are about the Air Quality dataset by County in the United States and Italy, concentrating on the yearly, daily and hourly data.\nYou can access the application from here .\nYou can learn more about the application here.\nThe code for the application is available on github .\nAn short video demonstration of the application is available on youtube .\n","date":1553104800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550690580,"objectID":"e722f61a75a360faf59fc6c02c54bc82","permalink":"https://bhavesh00.github.io/project/evlproject2/","publishdate":"2019-03-20T13:00:00-05:00","relpermalink":"/project/evlproject2/","section":"project","summary":"Visualization and Visual Analytics - Project 2!!","tags":["Visualization"],"title":"Every Breath You Take !!","type":"project"},{"authors":null,"categories":null,"content":"Group:\n Ashwani Khemani Abhishek Vasudevan Varsha Jayaraman  Abhishek solution:\n The UI is easy to navigate and it\u0026rsquo;s easy to follow things on the screen. The colors are pleasing and they work for the color blind people. The different charts had error messages for the case when no data was found for given user input.  Ashwani solution:\n The overall work done by him was good. He has organized the different visualizations properly. The pie charts created for the AQI were visually appealing and the labeling of the charts was done in a correct manner.  Varsha solution:\n The way she made use different colors and the display was very pleasant. The comparisons for more than one county was done in a unique way which makes the comparisons more intuitive. All the charts and tables have good color and proper labeling and make it easier for the user to analyze the information.  ","date":1550012400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550013780,"objectID":"2dd32f5a2e32f8cffa1e07785704b8cf","permalink":"https://bhavesh00.github.io/post/project1group/","publishdate":"2019-02-12T17:00:00-06:00","relpermalink":"/post/project1group/","section":"post","summary":" Interesting things in our Just Breathe project group !!","tags":["Visualization"],"title":"Just Breathe Group - Interesting Things !!","type":"post"},{"authors":null,"categories":null,"content":"This page contains the link to the visualization solution optimized for the EVL classroom wall and a description of how to use the application and the things that can be done with it.\nProject Link\nYoutube Link\nTo use this application follow the following steps :\nThe home page consists of a shiny dashboard with a side menu to choose what type of visualization user wants to see. The side menu has two options:\n One County - visualization consisting of one county. Multiple County - visualization consisting of more than one county  One the user select a side menu option, the corresponding page for the visualization loads.\n One County:  In this page, there are three input options for the user to select. The user has to select one of the available options in the drop down menu in a sequential order.\n Year State County\n  The user will then be able to see the different visualization on the screen below by navigating the different tabs provided in the panels below.\nThe first panel has three visualizations for the Air Quality of the state,county and year selected by the user:\n pie chart showing the percentage of days where the AQI could be good / moderate / unhealthy for sensitive / unhealthy / very unhealthy / hazardous a bar chart showing the number of days where the AQI could be good / moderate / unhealthy for sensitive / unhealthy / very unhealthy / hazardous table showing the number of days where the AQI could be good / moderate / unhealthy for sensitive / unhealthy / very unhealthy / hazardous  The second panel has eight visualizations based on the user input of state , county and year:\n pie chart for each individual pollutant (CO, NO2, Ozone, SO2, PM2.5, PM10 ) showing the percentage of days in the year with that pollutant as the main pollutant (6 charts)\n bar chart showing the number of CO, NO2, Ozone, SO2, PM2.5, PM10 days as the main pollutant\n table showing the number of CO, NO2, Ozone, SO2, PM2.5, PM10 days as the main pollutant\n  The third panel has 9 visualizations based on the user input of state , county and year:\n a line graph using the annual data from 1980-2018 showing lines for the median, 90th percentile, and max AQI over those years (i.e. the graph should have 3 lines) a line graph showing the percentages over the years for days CO / days NO2 / days Ozone, days SO2 / days PM2.5 / days pm10 (i.e. the graph should have 6 lines) 6 tables showing the percentages over the years for days CO / days NO2 / days Ozone, days SO2 / days PM2.5 / days pm10\n location of the chosen county on a pannable and zoomable world map  Here is a snapshot from the application .\n","date":1549933200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550700000,"objectID":"5b831a7882fc52d91a0caed8d04c268b","permalink":"https://bhavesh00.github.io/project/evlproject1/","publishdate":"2019-02-11T19:00:00-06:00","relpermalink":"/project/evlproject1/","section":"project","summary":"Visualization and Visual Analytics - Project 1 !!","tags":["Visualization"],"title":"Just Breathe !!","type":"project"},{"authors":null,"categories":null,"content":"The code for the project can be found here .\nThe data needed for the project is available in the root folder and the map data is available in the map folder of the project.\nThe instructions to run the code:\n Online : The project can be run through this link\n Offline : To run the project in the local environment , please follow the below instructions.\n Download the R-language from the R-website\n Download R-Studio free version from this website R-Studio and then install it your system.\n Once R-Studio is installed, open the R-Studio using the application file and download the following packages in R-Studio:\n library(shiny) library(shinydashboard) library(ggplot2) library(lubridate) library(DT) library(jpeg) library(grid) library(leaflet) library(scales)   The packages can be downloaded using the packages menu on the right side in R-Studio home screen. Search the package by name and install the above packages.\n Once the packages are installed, the user can open the project from source code link provided here .\n To run the applications, open the app.R and click on Run App button on the upper right side of app.R file screen.\n The user should now be able to see the various visualization done as part of the Just-Breathe application.\n The entire source code has been written using R language and using packages above.\n  ","date":1549933200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549934580,"objectID":"980ade52fc1f61c73034679e98d1f913","permalink":"https://bhavesh00.github.io/post/evlproject1code/","publishdate":"2019-02-11T19:00:00-06:00","relpermalink":"/post/evlproject1code/","section":"post","summary":"Visualization and Visual Analytics - Project 1 - Code !!","tags":["Visualization"],"title":"Just Breathe - Code !!","type":"post"},{"authors":null,"categories":null,"content":"The page contains information about the data used in the Just Breathe project. The data was downloaded from the EPA website.\nThe link to download the data is here\nThe files for annual summary of data for counties was downloaded from years 1980-2018.\nThe files were then extracted and imported using R Studio to create visualization as described in the project\n","date":1549933200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549934580,"objectID":"42df8046b2940d6be1e1d6203a0f8847","permalink":"https://bhavesh00.github.io/post/evlproject1data/","publishdate":"2019-02-11T19:00:00-06:00","relpermalink":"/post/evlproject1data/","section":"post","summary":"Visualization and Visual Analytics - Project 1 - Data !!","tags":["Visualization"],"title":"Just Breathe - Data!!","type":"post"},{"authors":null,"categories":null,"content":"Project Link\nInteresting things which were found about the data using the application.\nThe findings are given below for the Cook county of Illinois.\n Amongst the pollutants, SO2 pollutant has shown a relatively downward trend over the last 25 years with some exceptions in certain years. PM2.5 pollutant has shown a relatively upward trend over the last 25 years with some exceptions in certain years. CO , Carbon monozide emission has been neglible over the last 20 years  These trends show that there has been an effor to reduce harmful emissions but at the same time there are still emissions that need to be controlled to bring them under permissible range.\n While comparing different states and their counties, the air Quality in Cook county in Illinois was found to be worse as comapred to those in Florida state.\n States like Nebraska , Utah have comparitively good air quality as compared to states like Illinois, California. The counties in these states with less population show air quality as expected. The states and the counties which large population and industry are prone to bad air quality.\n  ","date":1549933200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549934580,"objectID":"b64de85403a8a33ca9151ee653977037","permalink":"https://bhavesh00.github.io/post/evlproject1findings/","publishdate":"2019-02-11T19:00:00-06:00","relpermalink":"/post/evlproject1findings/","section":"post","summary":"Visualization and Visual Analytics - Project 1 - Findings!!","tags":["Visualization"],"title":"Just Breathe --Findings !!","type":"post"},{"authors":null,"categories":null,"content":"","date":1548874440,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517338440,"objectID":"a91f989321140d9b4c5085eb998df9ad","permalink":"https://bhavesh00.github.io/post/color_test/","publishdate":"2019-01-30T12:54:00-06:00","relpermalink":"/post/color_test/","section":"post","summary":"The X-Rite Color Challenge and Hue Test !!","tags":["Visualization"],"title":"The X-Rite Color Challenge and Hue Test !!","type":"post"},{"authors":null,"categories":null,"content":"Here is the link to the website deployed using shinny apps account\nEVL Weather\n","date":1548378000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1516843380,"objectID":"b4bab45c65267cbff89ce7e58f3aefec","permalink":"https://bhavesh00.github.io/post/evl/","publishdate":"2019-01-24T19:00:00-06:00","relpermalink":"/post/evl/","section":"post","summary":"EVL Weather Application !!","tags":["Visualization"],"title":"EVL Weather Application !!","type":"post"},{"authors":null,"categories":null,"content":"I get my weather updates from the weather channel !!! I usually visit weather channel because it provides the most accurate and up to date weather updates. It shows hourly, daily and weekly weather forecast in an organized manner. The website and phone application are easy to navigate and to use. I highly recommend the application to everyone.\n","date":1547773200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1516238580,"objectID":"e836cb5af2f2f58978227079c8d56ded","permalink":"https://bhavesh00.github.io/post/weather/","publishdate":"2019-01-17T19:00:00-06:00","relpermalink":"/post/weather/","section":"post","summary":"From where to get weather updates !!","tags":["Visualization"],"title":"Weather Updates !!","type":"post"},{"authors":[],"categories":null,"content":"A few days ago I read the following tweet somewhere on the internet !!\nWhen you’ve written the same code 3 times, write a function\nWhen you’ve given the same in-person advice 3 times, write a blog post\n\u0026mdash; David Robinson (@drob) November 9, 2017 \nI tried to relate it to my real life experience and it definitely did make a lot of sense. I have seen myself sometimes repeating and sharing the same advice with my friends and colleagues. So, I decided to start my own blog to share my learnings and experiences with everyone.\nI enjoy reading and have become an avid reader (I would have been surprised if someone said that about me a couple of years ago). I love to read about a lot of varied topics and yes anything related to the computers (we go long way back) and the technology. Currently, I am more occupied with reading academic texts and papers about topics of my interests and I would love to share anything I find interesting in them. Apart from reading, I really enjoy sharing my knowledge with people which is the main motivation behind this blog.\nTalking to people who are new to the field or are nervous because of the initial experience with something and helping them is something I have always cherished. \u0026ldquo;Success is not counted by how high you have climbed but by how many people you brought with you\u0026rdquo;.And I try to stand by this each and every day of my life. I do sometimes digress to philosophy even when I try very hard not to, I promise I would avoid it in the future posts :) But, coming back to the purpose of this blog and the interests that I would like to talk about here.\nI currently find the areas of machine learning and distributed systems very fascinating. I would love to share my perspective about different concepts and try to make topics in these areas more interesting and understandable.\nI recently read an article which talked about deep learning, I apologize for the jargon. Let\u0026rsquo;s for now not focus on what does it mean as it\u0026rsquo;s not that important at the moment. The article said that the fact that deep learning is hyped is itself hyped. I agree with it as people are trying to make use of buzzwords to gain traction and there is nothing wrong with that. My point is, yes, it may be hyped, but what differentiates a genuine enthusiast and person who wants to make use of any form of science and technology is not how much hype one can create, it\u0026rsquo;s about how much impact one can have with their creation over the world and its population. This is the sole reason behind my curiosity about machine learning and distributed systems. I think they are very useful and if people try to make use of them to solve real-world problems, the opportunities are endless !!\nI might sometimes write about some non-technical topics also, but I would try to keep them separate. I have found the internet and online communities very useful for the knowledge I have gained in my life. This is my way to give something back to it !! I hope this blog would be useful for everyone and I would love to hear your comments and feedback.\nStay tuned !!!\n","date":1538184180,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538187780,"objectID":"ba6423d815d4f5949b7a69912feb741d","permalink":"https://bhavesh00.github.io/post/getting-started/","publishdate":"2018-09-28T20:23:00-05:00","relpermalink":"/post/getting-started/","section":"post","summary":"Start of something exciting !!","tags":["others"],"title":"Time for a new beginning !!","type":"post"},{"authors":null,"categories":null,"content":" Investigated many Devops pipeline programs and obtained statistical data that describe content and patterns in Devops pipelines.\n Java, Jenkins, GitHub\n  Source Code available here.\n","date":1537592400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537592400,"objectID":"2c0e1c5341dc83c08489e133b4ebf2c6","permalink":"https://bhavesh00.github.io/project/pa/","publishdate":"2018-09-22T00:00:00-05:00","relpermalink":"/project/pa/","section":"project","summary":"Comprehensive analysis of Devops pipelines","tags":["DevOps"],"title":"An Empirical Investigation into Large-Scale Devops Pipeline programs","type":"project"},{"authors":null,"categories":null,"content":" Designed and developed parallel optimization algorithm based on the LBFGS solver provided by PETSc, leveraging its parallel primitives and testing the scalability on cluster Implemented stochastic gradient solvers (SGD and ADAM), and tested their efficiency in comparison with LBFGS  Source Code available here.\n","date":1537592400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537592400,"objectID":"c7f19c2080d957ec72f0f578592e522d","permalink":"https://bhavesh00.github.io/project/crf/","publishdate":"2018-09-22T00:00:00-05:00","relpermalink":"/project/crf/","section":"project","summary":"Parallel and Stochastic optimization of Conditional Random Field for optical character recognition (OCR)","tags":["machine-learning"],"title":"Conditional Random Field for optical character recognition (OCR)","type":"project"},{"authors":null,"categories":null,"content":" Created a DevOps application workflow for automatically building and analyzing software applications statically as part of the workflow to obtain information about relationships among components of these applications. Java, Jenkins, Gitlab, GitHub  Source Code available here .\n","date":1537592400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537592400,"objectID":"730622d356f770675d2c182a2f642534","permalink":"https://bhavesh00.github.io/project/do/","publishdate":"2018-09-22T00:00:00-05:00","relpermalink":"/project/do/","section":"project","summary":"Simulation of end to end DevOps workflow","tags":["DevOps"],"title":"DevOps Orchestration to simulate end to end DevOps workflow at an enterprise level","type":"project"},{"authors":null,"categories":null,"content":"The Mask R-CNN (Regional Convolutional Neural Network) can be used in instance segmentation, and has been quite sucessful when compared with other architectures for the same task. In this project we look at its performance on two well known datasets, cityscapes and CSAIL Places, and try to see the impact of modifying hyperparameters and using different network architectures in the backbone.\n Summary of the Problem Instance Segmentation is the combination of three other tasks making it very difficult. Those three tasks are Image Classification, Object Detection, and Semantic Segmentation. See Figure 1 for an overview of the task.   Instance Segmentation\nImage Classification, being the most studied of the three, is a task where you are given an image and the goal is to classify it. Examples of such studies are those done on the MNIST dataset [1]. In MNIST, the task is to classify handwritten digits given only an image of the digit. Some of the most successful approaches involve CNN architectures, like VGG, GoogleLeNet, ResNet, and many others. Object Detection has the same domain, but the goal is to find all instances of an object and find the smallest bounding box around the object. One way to structure this as a machine learning task is to formulate it as a Regression problem, where the bounding box is defined by a set of coordinates. This is done in our Mask R-CNN implementation and its immediate predecessor, Faster R-CNN [2]. The goal of Semantic Segmentation is to classify each pixel, effectively segmenting an image into its semantic components. This was a difficult task because there was no obvious way to generate predictions for each pixel, without feeding the whole image multiple times through a traditional CNN classification network, and this would make the problem intractable. One well known solution to this is to use a Fully Convolutional Network (FCN), which would have an Encoder/Decoder structure by first using Convolution Layers and Pooling\n Cityscapes Cityscapes has data from street scenes, so an application of a network trained on this dataset is autonomous vehicles. The dataset has approximately 5,000 examples and 30 classes with fine grain annotations. We used about 3,500 for training and 500 for validation.\n CSAIL Places This dataset is more general and has a wide variety of scenes. It has approximately 20K examples (2K validation), with annotations, and 100 classes. The CSAIL places dataset will give us an opportunity to compare our results with work published that tested with more popular datasets like MSCOCO [4].\n Mask R-CNN Architecture\n  ","date":1537592400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537592400,"objectID":"ab53399cabd74b2e9f3914a5627002ef","permalink":"https://bhavesh00.github.io/project/maskrcnn/","publishdate":"2018-09-22T00:00:00-05:00","relpermalink":"/project/maskrcnn/","section":"project","summary":"Instance Segmentation using Convolutional Neural Networks","tags":["machine-learning"],"title":"Instance Segmentation using Convolutional Neural Networks","type":"project"},{"authors":null,"categories":null,"content":" Performed Monte-Carlo simulation for evaluation of stock purchase decisions that runs on Spark and deployed on private OctaPi cloud using Kubernetes Java, Spark, Docker, K8s  Source Code available here .\n","date":1537592400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537592400,"objectID":"f09b93d28e84184bf0b2750b16219988","permalink":"https://bhavesh00.github.io/project/mcs/","publishdate":"2018-09-22T00:00:00-05:00","relpermalink":"/project/mcs/","section":"project","summary":"Evaluation of stock investment decisions using Monte-Carlo simulation and OctaPi cloud","tags":["Cloud"],"title":"Monte-Carlo simulation with OctaPi cloud","type":"project"},{"authors":null,"categories":null,"content":" Built and designed an OctaPi cloud cluster of Raspberry PI devices to run a Hadoop map/reduce application to make software testing process parallel and efficient Automated deploying, scaling, and operating application containers on Raspberry Pi using Kubernetes Java, Hadoop, Docker, K8s  Source Code available here .\n","date":1537592400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537592400,"objectID":"ffce5bc471c746c2d8d11b199640d7e3","permalink":"https://bhavesh00.github.io/project/st/","publishdate":"2018-09-22T00:00:00-05:00","relpermalink":"/project/st/","section":"project","summary":"Automation of software testing process using Hadoop","tags":["Cloud"],"title":"Parallelization of software testing using Hadoop Map-Reduce model and OctaPi Cluster","type":"project"},{"authors":null,"categories":null,"content":" Conducted comparative study of Machine Learning and Deep Learning models for Sentiment Analysis Designed deep learning models to achieve state of the art performance on complex task such as sentiment analysis on twitter dataset  Source Code available here .\n","date":1537592400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537592400,"objectID":"1e6260de844a02b205bddca42ade9aac","permalink":"https://bhavesh00.github.io/project/sm/","publishdate":"2018-09-22T00:00:00-05:00","relpermalink":"/project/sm/","section":"project","summary":"Sentiment Analysis of Twitter Corpus","tags":["machine-learning"],"title":"Sentiment Analysis of Twitter Corpus","type":"project"},{"authors":null,"categories":null,"content":" Obtained information about program entities that were modified because of fixes to specific bugs/issues and found useful pattern amongst them using static code analysis tool like Understand Python, GitHub, Understand  Source Code available here.\n","date":1537592400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537592400,"objectID":"5743653686b326694095c44c8ad1ea52","permalink":"https://bhavesh00.github.io/project/sca/","publishdate":"2018-09-22T00:00:00-05:00","relpermalink":"/project/sca/","section":"project","summary":"Checking the open source projects for the frequently occuring issues","tags":["DevOps"],"title":"Static Code Analyzer to find most common bugs in Open Source Projects","type":"project"},{"authors":null,"categories":null,"content":" Developed a conditional random field model for Optical Character Recognition (OCR), with emphasis on inference and performance test Performed benchmarking by comparing CRF with multi-class linear SVM  Source Code available here .\n","date":1537592400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537592400,"objectID":"6dc0692cb8ed303095aec81aa6bee6a5","permalink":"https://bhavesh00.github.io/project/crf_1/","publishdate":"2018-09-22T00:00:00-05:00","relpermalink":"/project/crf_1/","section":"project","summary":"Conditional Random Field for optical character recognition (OCR)","tags":["machine-learning"],"title":"Structured Output Prediction using Conditional Random Fields","type":"project"}]